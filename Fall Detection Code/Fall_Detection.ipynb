{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDysuIspGANj",
        "outputId": "8c09c688-5bee-427e-a32f-be5c938e1c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=22.04\n",
            "DISTRIB_CODENAME=jammy\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.2 LTS\"\n",
            "PRETTY_NAME=\"Ubuntu 22.04.2 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.2 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ],
      "source": [
        "!cat /etc/*-release"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ75sW1mGGrr",
        "outputId": "1460cf0c-fc5a-473a-cb4c-61be2071f257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RS49T5bGGuS",
        "outputId": "5f18fac6-fab1-43d9-87ac-edb8377c27d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 15:44:17--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 190 [application/octet-stream]\n",
            "Saving to: ‘cuda-ubuntu2204.pin’\n",
            "\n",
            "\rcuda-ubuntu2204.pin   0%[                    ]       0  --.-KB/s               \rcuda-ubuntu2204.pin 100%[===================>]     190  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-24 15:44:17 (3.01 MB/s) - ‘cuda-ubuntu2204.pin’ saved [190/190]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600"
      ],
      "metadata": {
        "id": "GCUcT8uxGGxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiMqIgdgGG0H",
        "outputId": "57bd67de-d377-45c9-9537-c84fe60738ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 15:44:27--  https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3269505662 (3.0G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu220 100%[===================>]   3.04G   127MB/s    in 33s     \n",
            "\n",
            "2023-10-24 15:45:00 (93.3 MB/s) - ‘cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb’ saved [3269505662/3269505662]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo dpkg -i cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8mVmktxGG27",
        "outputId": "ce55bd37-2d79-471b-98c5-0383afaad8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m dpkg frontend lock was locked by another process with pid 795\n",
            "Note: removing the lock file is always wrong, and can end up damaging the\n",
            "locked area and the entire system. See <https://wiki.debian.org/Teams/Dpkg/FAQ>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo cp /var/cuda-repo-ubuntu2204-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/\n"
      ],
      "metadata": {
        "id": "8VkgGmXNGG5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5358bcc6-1709-4de6-8a2e-dda05e828e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/var/cuda-repo-ubuntu2204-12-2-local/cuda-*-keyring.gpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKVOtcaaGG8U",
        "outputId": "3ee96d07-ca3b-4fa1-c2f9-783c4a98f492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,009 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [555 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,131 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,398 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,330 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.7 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [40.1 kB]\n",
            "Fetched 7,150 kB in 3s (2,392 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z53CJTrlgckM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get -y install cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r269PL56GG_R",
        "outputId": "860fd859-8cc6-4a60-8a21-8306ed149cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Could not get lock /var/lib/dpkg/lock-frontend. It is held by process 795 (apt-get)\n",
            "N: Be aware that removing the lock file is not a solution and may break your system.\n",
            "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYYRyx6tgdvP",
        "outputId": "8d3f8c07-65c5-4a32-a50d-4db65e0a8ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dominate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f772UWhIgWyt",
        "outputId": "d38a6324-9d4a-4230-d33f-fca932d17637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dominate\n",
            "  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tM1ELnCL_Qg",
        "outputId": "64fc0267-96a5-48c0-c919-f91740b394af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lijx10/SO-Net.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ5vlcEYL_TS",
        "outputId": "188f9446-4d07-441a-d578-f0e3561919dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uV_CVvVIgbsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4aba215-4ffb-4f10-b875-ffece221236a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index-max error\n",
        "import os\n",
        "new_directory = \"/content/SO-Net/models/index_max_ext\"\n",
        "os.chdir(new_directory)\n",
        "!python3 setup.py install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkpuOyo8D21m",
        "outputId": "38488c55-8d06-48b1-d5c9-585d2d72495e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating index_max.egg-info\n",
            "writing index_max.egg-info/PKG-INFO\n",
            "writing dependency_links to index_max.egg-info/dependency_links.txt\n",
            "writing top-level names to index_max.egg-info/top_level.txt\n",
            "writing manifest file 'index_max.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:502: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'index_max.egg-info/SOURCES.txt'\n",
            "writing manifest file 'index_max.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'index_max' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c index_max.cpp -o build/temp.linux-x86_64-cpython-310/index_max.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=index_max -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor index_max_forward_cuda_wrapper(at::Tensor, at::Tensor, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  119 | #define CHECK_CUDA(x) AT_ASSERTM(x.type\u001b[01;35m\u001b[K(\u001b[m\u001b[K).is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:303:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  303 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:323:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  323 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:375:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  375 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:668:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  668 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  119 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:121:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "  121 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:135:9:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  135 |         \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(data);\n",
            "      |         \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  119 | #define CHECK_CUDA(x) AT_ASSERTM(x.type\u001b[01;35m\u001b[K(\u001b[m\u001b[K).is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:303:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  303 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:323:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  323 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:375:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  375 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:668:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  668 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  119 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:121:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "  121 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:136:9:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  136 |         \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(index);\n",
            "      |         \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor index_max_forward_cuda_wrapper_shared_mem(at::Tensor, at::Tensor, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  119 | #define CHECK_CUDA(x) AT_ASSERTM(x.type\u001b[01;35m\u001b[K(\u001b[m\u001b[K).is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:303:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  303 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:323:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  323 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:375:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  375 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:668:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  668 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  119 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:121:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "  121 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:144:9:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  144 |         \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(data);\n",
            "      |         \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  119 | #define CHECK_CUDA(x) AT_ASSERTM(x.type\u001b[01;35m\u001b[K(\u001b[m\u001b[K).is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:303:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  303 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:323:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  323 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:375:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  375 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Exception.h:668:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  668 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:119:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  119 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor/variable\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:121:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "  121 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max.cpp:145:9:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  145 |         \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(index);\n",
            "      |         \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kindex_max.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c index_max_cuda.cu -o build/temp.linux-x86_64-cpython-310/index_max_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=index_max -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor index_max_forward_cuda(at::Tensor, at::Tensor, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:75:104:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 |         index_max_forward_cuda_kernel<<<C, B>>>(data.data<float>(),\n",
            "      |                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:75:125:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 |         index_max_forward_cuda_kernel<<<C, B>>>(data.data<float>(),\n",
            "      |                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:75:148:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 |         index_max_forward_cuda_kernel<<<C, B>>>(data.data<float>(),\n",
            "      |                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:75:173:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 |         index_max_forward_cuda_kernel<<<C, B>>>(data.data<float>(),\n",
            "      |                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor index_max_forward_cuda_shared_mem(at::Tensor, at::Tensor, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:93:140:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   93 |         index_max_forward_cuda_kernel_shared_mem<<<C, B, B*K*sizeof(float)>>>(data.data<float>(),\n",
            "      |                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:93:161:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   93 |         index_max_forward_cuda_kernel_shared_mem<<<C, B, B*K*sizeof(float)>>>(data.data<float>(),\n",
            "      |                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:93:184:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   93 |         index_max_forward_cuda_kernel_shared_mem<<<C, B, B*K*sizeof(float)>>>(data.data<float>(),\n",
            "      |                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kindex_max_cuda.cu:93:209:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   93 |         index_max_forward_cuda_kernel_shared_mem<<<C, B, B*K*sizeof(float)>>>(data.data<float>(),\n",
            "      |                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/index_max.o build/temp.linux-x86_64-cpython-310/index_max_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/index_max.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/index_max.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for index_max.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/index_max.py to index_max.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying index_max.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying index_max.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying index_max.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying index_max.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.index_max.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/index_max-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing index_max-0.0.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/index_max-0.0.0-py3.10-linux-x86_64.egg\n",
            "Extracting index_max-0.0.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding index-max 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/index_max-0.0.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for index-max==0.0.0\n",
            "Finished processing dependencies for index-max==0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "new_directory = \"/content/SO-Net\"\n",
        "os.chdir(new_directory)\n"
      ],
      "metadata": {
        "id": "EXy0J-PM1AoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python modelnet/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F51KQzCSD49",
        "outputId": "65a926cb-6313-495c-f2a9-338aa0322771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "activation: relu\n",
            "batch_size: 8\n",
            "bn_momentum: 0.1\n",
            "bn_momentum_decay: 0.6\n",
            "bn_momentum_decay_step: None\n",
            "checkpoints_dir: ./checkpoints\n",
            "classes: 4\n",
            "dataroot: /content/drive/MyDrive/our dataset (temp)\n",
            "dataset: modelnet\n",
            "device: cuda:0\n",
            "display_id: 200\n",
            "display_winsize: 256\n",
            "dropout: 0.7\n",
            "feature_num: 1024\n",
            "gpu_id: 0\n",
            "input_pc_num: 1000\n",
            "k: 3\n",
            "lr: 0.001\n",
            "nThreads: 8\n",
            "name: train\n",
            "node_num: 64\n",
            "normalization: batch\n",
            "pretrain: None\n",
            "pretrain_lr_ratio: 1\n",
            "random_pc_dropout_lower_limit: 1\n",
            "rot_horizontal: False\n",
            "rot_perturbation: False\n",
            "som_k: 9\n",
            "som_k_type: avg\n",
            "surface_normal: False\n",
            "translation_perturbation: False\n",
            "-------------- End ----------------\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "#training point clouds = 255\n",
            "Tested network. So far best: 0.481818\n",
            "Tested network. So far best: 0.672727\n",
            "Tested network. So far best: 0.800000\n",
            "Tested network. So far best: 0.800000\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.836364\n",
            "update encoder learning rate: 0.001000 -> 0.000500\n",
            "update classifier learning rate: 0.001000 -> 0.000500\n",
            "Tested network. So far best: 0.836364\n",
            "Tested network. So far best: 0.845455\n",
            "Tested network. So far best: 0.845455\n",
            "Tested network. So far best: 0.845455\n",
            "Tested network. So far best: 0.845455\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.854545\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "update encoder learning rate: 0.000500 -> 0.000250\n",
            "update classifier learning rate: 0.000500 -> 0.000250\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.863636\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000250 -> 0.000125\n",
            "update classifier learning rate: 0.000250 -> 0.000125\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000125 -> 0.000063\n",
            "update classifier learning rate: 0.000125 -> 0.000063\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000063 -> 0.000031\n",
            "update classifier learning rate: 0.000063 -> 0.000031\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000031 -> 0.000016\n",
            "update classifier learning rate: 0.000031 -> 0.000016\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000016 -> 0.000010\n",
            "update classifier learning rate: 0.000016 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "Tested network. So far best: 0.881818\n",
            "update encoder learning rate: 0.000010 -> 0.000010\n",
            "update classifier learning rate: 0.000010 -> 0.000010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "new_directory = \"/content/SO-Net\"\n",
        "os.chdir(new_directory)"
      ],
      "metadata": {
        "id": "iZSxclKosfLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python part-seg/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLK-0OTdsRf7",
        "outputId": "d30e8201-84a4-4401-8ee6-b2c214fafc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "activation: relu\n",
            "batch_size: 8\n",
            "bn_momentum: 0.1\n",
            "bn_momentum_decay: 0.6\n",
            "bn_momentum_decay_step: None\n",
            "checkpoints_dir: ./checkpoints\n",
            "classes: 50\n",
            "dataroot: /content/drive/MyDrive/datasets/shapenetcore_partanno_segmentation_benchmark_v0_normal\n",
            "dataset: shapenet\n",
            "device: cuda:0\n",
            "display_id: 200\n",
            "display_winsize: 256\n",
            "dropout: 0.6\n",
            "feature_num: 1024\n",
            "gpu_id: 0\n",
            "input_pc_num: 1024\n",
            "k: 3\n",
            "lr: 0.001\n",
            "nThreads: 8\n",
            "name: train\n",
            "node_num: 64\n",
            "normalization: batch\n",
            "pretrain: None\n",
            "pretrain_lr_ratio: 1\n",
            "random_pc_dropout_lower_limit: 1\n",
            "som_k: 9\n",
            "som_k_type: center\n",
            "surface_normal: True\n",
            "-------------- End ----------------\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "#training point clouds = 12136\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.697881\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.733546\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.750697\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.757624\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.771773\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.774637\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.781476\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.786685\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.788064\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.794119\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.795336\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.795336\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.804423\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.804423\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.804423\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.804423\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.804423\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.810145\n",
            "2874\n",
            "Tested network. So far best segmentation: 0.810145\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SO-Net/part-seg/train.py\", line 60, in <module>\n",
            "    model.optimize()\n",
            "  File \"/content/SO-Net/models/segmenter.py\", line 120, in optimize\n",
            "    self.loss_segmenter.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 492, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}